# ============================================================================
# BoeNet v3.2.0 Phase 3: COMPREHENSIVE SWEEP
# ============================================================================
#
# PURPOSE: Now that training takes MINUTES instead of HOURS, run a complete
#          exploration of the entire parameter space to find optimal config.
#
# ============================================================================
# THE BREAKTHROUGH: TRAINING IS NOW FAST
# ============================================================================
#
# WHAT WE FIXED IN THIS SESSION:
# ------------------------------
#
# PROBLEM 1: GrowthPolicyNet was DEAD (v2.3.1 and earlier)
#   - grow_prob = 0.0000 for ALL inputs
#   - Trees NEVER expanded except forced by epsilon-greedy
#   - Training took HOURS spinning uselessly
#
# ROOT CAUSE:
#   - model.py defined its own broken GrowthPolicyNet
#   - LayerNorm + ReLU architecture killed all activations
#   - Logits were -16 or lower â†’ sigmoid(âˆ’16) â‰ˆ 0.0000
#
# FIX APPLIED (v2.4.0):
#   - DELETED broken GrowthPolicyNet from model.py
#   - IMPORTED working GrowthPolicyNet from gating.py (v3.1.0)
#   - Now grow_prob â‰ˆ 0.5 (healthy, learnable)
#
# PROBLEM 2: Node count metrics showed 0.0 (v3.1.0)
#   - avg_nodes_per_position = 0.0 in CSV
#   - But logs showed trees WERE expanding (total_nodes=7)
#
# ROOT CAUSE:
#   - Calculation divided by (positions * rollouts) instead of just rollouts
#   - 15 / (8192 * 3) = 0.0006 â‰ˆ 0.0
#
# FIX APPLIED (v3.2.0):
#   - node_counts = tree structure sizes [1, 7, 3, ...]
#   - avg_nodes = mean(node_counts) = correct value
#
# RESULT:
#   | Metric              | Before (Broken) | After (Fixed)   |
#   |---------------------|-----------------|-----------------|
#   | Training time       | HOURS           | ~5 MINUTES      |
#   | grow_prob           | 0.0000          | ~0.5            |
#   | avg_nodes           | 0.0             | 1.27            |
#   | avg_depth           | 0.0             | 0.12            |
#   | Trees expanding     | âŒ Never        | âœ… Yes          |
#   | Policy learning     | âŒ Frozen       | âœ… Active       |
#
# ============================================================================
# WHY COMPREHENSIVE SWEEP NOW MAKES SENSE
# ============================================================================
#
# OLD SITUATION (Broken):
#   - Each run took hours
#   - Limited to ~6 runs
#   - Guessing at parameters
#
# NEW SITUATION (Fixed):
#   - Each run takes ~5 minutes
#   - Can run 100+ configurations
#   - Data-driven decisions
#
# SWEEP CALCULATION:
#   - k values: 4 (0, 2, 3, 4)
#   - depths: 5 (0, 2, 3, 4, 5)  
#   - epochs: 6 (5, 10, 15, 20, 25, 30)
#   
#   But k=0 ignores depth, so:
#   - k=0: 1 Ã— 6 epochs = 6 runs
#   - k=2,3,4: 3 Ã— 5 depths Ã— 6 epochs = 90 runs
#   - Total: 96 runs Ã— ~5 min = ~8 hours
#
# This gives us COMPLETE data to answer:
#   1. Is tree structure worth it? (k=0 vs k>0)
#   2. What branching factor is optimal? (k=2 vs k=3 vs k=4)
#   3. Does deeper reasoning help? (depth=2 vs depth=5)
#   4. When does each config converge? (epochs 5â†’30)
#
# ============================================================================
# FILE VERSIONS REQUIRED FOR THIS SWEEP
# ============================================================================
#
# CRITICAL: Ensure these versions are deployed before running!
#
# | File                    | Version | Key Fix                           |
# |-------------------------|---------|-----------------------------------|
# | boenet/model.py         | v2.4.0  | Imports GrowthPolicyNet from gating |
# | boenet/utils/gating.py  | v3.1.0  | Fixed GrowthPolicyNet architecture |
# | train_boenet.py         | v3.2.0  | Fixed node count metric calculation |
#
# VERIFICATION:
#   - model.py should have: from boenet.utils.gating import GrowthPolicyNet
#   - gating.py GrowthPolicyNet.forward() should return shape [N] not [N,1]
#   - train_boenet.py should compute: avg = sum(tree_sizes) / len(tree_sizes)
#
# ============================================================================
# TREE STRUCTURE VISUALIZATION
# ============================================================================
#
# k=0 (Dense - No Tree):
#   [Root] â†’ Output
#   Nodes: 1 (always)
#
# k=2 (Binary Tree):
#
#   DEPTH=0: [Root] â†’ 1 node
#   
#   DEPTH=2: 
#            Root
#           /    \
#          A      B
#         / \    / \
#        1   2  3   4
#        â†’ 7 nodes (1+2+4)
#   
#   DEPTH=3:
#                 Root
#               /      \
#              A        B
#             / \      / \
#            1   2    3   4
#           /\ /\    /\ /\
#          8 leaf nodes
#          â†’ 15 nodes (1+2+4+8)
#   
#   DEPTH=4:
#          â†’ 31 nodes (1+2+4+8+16)
#   
#   DEPTH=5:
#          â†’ 63 nodes (1+2+4+8+16+32)
#
# k=3 (Ternary Tree):
#   DEPTH=2: 1+3+9 = 13 nodes
#   DEPTH=3: 1+3+9+27 = 40 nodes
#   DEPTH=4: 1+3+9+27+81 = 121 nodes
#
# k=4 (Quaternary Tree):
#   DEPTH=2: 1+4+16 = 21 nodes
#   DEPTH=3: 1+4+16+64 = 85 nodes
#   DEPTH=4: 1+4+16+64+256 = 341 nodes
#
# ============================================================================
# REASONING INTERPRETATION BY DEPTH
# ============================================================================
#
# Depth=0: "What's the answer?" (immediate response)
# Depth=1: "What's likely? â†’ Refine" (one reasoning step)
# Depth=2: "Likely? â†’ Yes/No â†’ Confidence" (two steps)
# Depth=3: "Likely? â†’ Direction â†’ Confidence â†’ Evidence" (three steps)
# Depth=4: "Likely? â†’ Direction â†’ Confidence â†’ Evidence â†’ Context" (four steps)
# Depth=5: "Full reasoning chain with maximum context" (five steps)
#
# HYPOTHESIS: More depth = More reasoning = Better predictions
#             But diminishing returns after some point
#
# ============================================================================

sweep:
  # ==========================================================================
  # LANGUAGE MODEL PARAMETERS (FIXED - PROVEN VALUES)
  # ==========================================================================
  
  # Vocabulary size: FIXED at 256 (character-level ByteTokenizer)
  vocab_size: 256
  
  # Sequence length: FIXED at 128 (good balance of context and speed)
  seq_len_list: [128]
  
  # Embedding dimension: FIXED at 64 (proven to work well)
  embed_dim_list: [64]
  
  # Dataset: WikiText-2 (consistent with all previous runs)
  dataset: wikitext2
  
  # ==========================================================================
  # K VALUES - COMPREHENSIVE (ALL BRANCHING FACTORS)
  # ==========================================================================
  #
  # k=0: Dense baseline (no tree structure)
  #      - Always 1 node per position
  #      - Fastest inference
  #      - Target to beat: PPL ~11.55
  #
  # k=2: Binary tree (our current best)
  #      - 2 children per node
  #      - GPU-efficient (power of 2)
  #      - Good sparsity behavior
  #      - Current result: PPL ~11.68 with avg_nodes=1.27
  #
  # k=3: Ternary tree
  #      - 3 children per node
  #      - More branching options
  #      - Historical: PPL ~11.63 at depth=2
  #
  # k=4: Quaternary tree
  #      - 4 children per node
  #      - Maximum branching tested
  #      - Historical: PPL ~11.70, sparsity hurts quality
  #
  k_values: [0, 2, 3, 4]
  
  # ==========================================================================
  # DEPTH VALUES - COMPREHENSIVE (ALL REASONING LEVELS)
  # ==========================================================================
  #
  # NOTE: For k=0, depth is ignored (always 1 node)
  #       For k>0, depth controls maximum tree expansion
  #
  # | Depth | k=2 Nodes | k=3 Nodes | k=4 Nodes | Reasoning Levels |
  # |-------|-----------|-----------|-----------|------------------|
  # | 0     | 1         | 1         | 1         | 1 (root only)    |
  # | 2     | 7         | 13        | 21        | 3 levels         |
  # | 3     | 15        | 40        | 85        | 4 levels         |
  # | 4     | 31        | 121       | 341       | 5 levels         |
  # | 5     | 63        | 364       | 1365      | 6 levels         |
  #
  # HYPOTHESIS: 
  #   - Depth matters more than k for quality
  #   - k=2 + high depth may beat k=4 + low depth
  #   - Diminishing returns after depth=4 or 5
  #
  max_depths: [0, 2, 3, 4, 5]
  
  # ==========================================================================
  # EPOCHS - COMPREHENSIVE CONVERGENCE ANALYSIS
  # ==========================================================================
  #
  # Testing convergence at multiple checkpoints:
  #
  # | Epochs | Purpose                                    |
  # |--------|-------------------------------------------|
  # | 5      | Quick baseline, early stopping point      |
  # | 10     | Standard training checkpoint              |
  # | 15     | Extended training                         |
  # | 20     | Deep training                             |
  # | 25     | Near-convergence check                    |
  # | 30     | Full convergence (ensure plateau)         |
  #
  # QUESTIONS TO ANSWER:
  #   - When does each (k, depth) combo converge?
  #   - Do deeper trees need more epochs?
  #   - Is there overfitting at high epochs?
  #
  epochs_list: [5, 10, 15, 20, 25, 30]
  
  # ==========================================================================
  # POLICY PARAMETERS - FIXED (PROVEN VALUES FROM PHASE 1)
  # ==========================================================================
  
  # Lambda efficiency: 0.05 (best from Phase 1)
  # Controls sparsity vs quality tradeoff
  # Higher = more pressure to use fewer nodes
  lambda_efficiency_list: [0.05]
  
  # Greedy threshold: 0.50 (enables adaptive sparsity)
  # During inference, expand only if grow_prob >= 0.50
  # This is where adaptive computation happens
  greedy_threshold_list: [0.50]
  
  # Number of rollouts: 3 (good exploration vs speed tradeoff)
  # More rollouts = better gradient estimates but slower training
  num_rollouts_list: [3]
  
  # Entropy bonus: 0.01 (encourages exploration)
  # Prevents policy from collapsing to always-expand or always-stop
  beta_entropy_list: [0.01]
  
  # Policy loss weight: 0.5 (balanced with LM loss)
  # How much the policy gradient affects total loss
  beta_policy_list: [0.5]
  
  # ==========================================================================
  # v3.1.0: EPSILON-GREEDY EXPLORATION
  # ==========================================================================
  #
  # min_explore_prob: 0.10 (10% forced expansion)
  # During training, 10% of decisions force tree expansion
  # This ensures trees actually expand during training
  # Without this, policy can get stuck at depth=0
  #
  min_explore_prob: 0.10
  
  # ==========================================================================
  # ARCHITECTURE PARAMETERS - FIXED
  # ==========================================================================
  
  # Hidden dimensions: 128 (good capacity for this task)
  hidden_dims: [128]
  
  # Pooling mode: mean (average all node representations)
  # Alternatives: sum, learned
  poolings: [mean]
  
  # ==========================================================================
  # OPTIMIZATION - FIXED (PROVEN VALUES)
  # ==========================================================================
  
  # Learning rate: 0.001 (standard for AdamW)
  lrs: [0.001]
  
  # Batch size: 64 (good GPU utilization)
  batch_sizes: [64]
  
  # Weight decay: 0.0 (no regularization needed for this scale)
  weight_decays: [0.0]
  
  # Gradient clipping: 1.0 (standard)
  grad_clip: 1.0
  
  # Policy gradient clipping: 0.5 (more aggressive for stability)
  policy_grad_clip: 0.5

# ============================================================================
# TRAINING SETTINGS
# ============================================================================
training:
  # Default epochs (overridden by epochs_list)
  epochs: 20
  
  # Single run per config (no repeats needed with fixed seed)
  repeats: 1
  
  # Random seed (consistent across all runs)
  seed0: 42
  
  # Dataset
  dataset: wikitext2
  
  # LR schedule
  lr_schedule: cosine
  
  # Optimizer
  optimizer: adamw

# ============================================================================
# INFERENCE SETTINGS
# ============================================================================
inference:
  # Number of samples for perplexity measurement
  infer_samples: 1000
  
  # Force CPU inference for fair latency comparison
  cpu_only: true
  
  # Enable policy analysis (shows grow_prob distribution)
  debug_policy: true

# ============================================================================
# PATHS
# ============================================================================
paths:
  # Output directory for all runs
  save_root: runs
  
  # Dataset directory
  data_root: ./data
  
  # Training script (v3.2.0 with fixed node counting)
  train_script: train_boenet.py
  
  # Inference script
  infer_script: infer_boenet.py

# ============================================================================
# RUN COUNT CALCULATION
# ============================================================================
#
# COMPREHENSIVE SWEEP:
#
# k=0 (depth ignored):
#   1 config Ã— 6 epochs = 6 runs
#
# k=2:
#   5 depths Ã— 6 epochs = 30 runs
#
# k=3:
#   5 depths Ã— 6 epochs = 30 runs
#
# k=4:
#   5 depths Ã— 6 epochs = 30 runs
#
# TOTAL: 6 + 30 + 30 + 30 = 96 runs
#
# TIME ESTIMATE:
#   - Average ~5 minutes per run (based on v3.2.0 performance)
#   - 96 runs Ã— 5 min = 480 min = ~8 hours
#
# COMPARISON TO OLD BROKEN SYSTEM:
#   - Old: Hours per run, limited exploration
#   - New: 8 hours for COMPLETE parameter space
#
# ============================================================================

# ============================================================================
# EXPECTED RESULTS AND HYPOTHESES
# ============================================================================
#
# BASELINE (k=0 dense):
#   - PPL: ~11.55 (target to match/beat)
#   - Latency: ~0.24 ms
#   - Always 1 node
#
# HYPOTHESIS 1: k=2 is optimal branching factor
#   - Binary trees are simplest
#   - GPU-efficient (power of 2)
#   - Good sparsity behavior
#   - Expected: k=2 â‰¤ k=3 < k=4 at same depth
#
# HYPOTHESIS 2: Depth matters more than k
#   - k=2 depth=4 should beat k=4 depth=2
#   - More reasoning levels > more branches per level
#   - Expected: depth=4 or 5 approaches k=0 quality
#
# HYPOTHESIS 3: Adaptive sparsity provides efficiency
#   - avg_nodes << max_nodes (currently 1.27 vs 31)
#   - Model uses minimal compute for easy tokens
#   - Model expands deeper for hard tokens
#
# HYPOTHESIS 4: Diminishing returns at high depth
#   - depth=5 may not beat depth=4 significantly
#   - Extra compute not worth marginal quality gain
#   - Sweet spot likely depth=3 or 4
#
# ============================================================================

# ============================================================================
# KEY COMPARISONS TO ANALYZE
# ============================================================================
#
# After sweep completes, analyze:
#
# 1. DENSE VS SPARSE:
#    | Config          | PPL    | Latency | Verdict     |
#    |-----------------|--------|---------|-------------|
#    | k=0             | 11.55  | 0.24ms  | baseline    |
#    | k=2 depth=4     | ???    | ???     | tree worth it? |
#
# 2. BRANCHING FACTOR (at depth=4):
#    | k | Max Nodes | PPL | avg_nodes | Efficiency |
#    |---|-----------|-----|-----------|------------|
#    | 2 | 31        | ??? | ???       | ???        |
#    | 3 | 121       | ??? | ???       | ???        |
#    | 4 | 341       | ??? | ???       | ???        |
#
# 3. DEPTH IMPACT (for k=2):
#    | Depth | Max Nodes | PPL    | Improvement |
#    |-------|-----------|--------|-------------|
#    | 2     | 7         | 11.68  | baseline    |
#    | 3     | 15        | ???    | vs depth=2  |
#    | 4     | 31        | ???    | vs depth=2  |
#    | 5     | 63        | ???    | vs depth=4  |
#
# 4. CONVERGENCE SPEED:
#    - Which configs converge fastest?
#    - Do deeper trees need more epochs?
#    - Is 30 epochs enough for all?
#
# 5. SPARSITY VS QUALITY:
#    - Plot: avg_nodes vs PPL
#    - Find Pareto frontier
#    - Identify optimal efficiency point
#
# ============================================================================

# ============================================================================
# USAGE INSTRUCTIONS
# ============================================================================
#
# PREREQUISITES:
#   1. Ensure v3.2.0 files are deployed:
#      - boenet/model.py (v2.4.0)
#      - boenet/utils/gating.py (v3.1.0)
#      - train_boenet.py (v3.2.0)
#
#   2. Clear Python bytecode cache:
#      find . -type d -name __pycache__ -exec rm -rf {} +
#
# START SWEEP:
#   docker run -d --gpus all --name boenet_comprehensive \
#     -v ${PWD}/data:/app/data \
#     -v ${PWD}/runs:/app/runs \
#     -v ${PWD}/configs:/app/configs \
#     -v ${PWD}/boenet:/app/boenet \
#     boenet:cuda python boenet_training_matrix.py \
#       --config configs/experiment-config.yaml
#
# MONITOR PROGRESS:
#   # Watch logs
#   docker logs -f boenet_comprehensive
#   
#   # Check GPU utilization
#   nvidia-smi -l 5
#   
#   # View results as they complete
#   docker exec boenet_comprehensive cat runs/*/matrix_results.csv
#
# STOP IF NEEDED:
#   docker stop boenet_comprehensive
#   docker rm boenet_comprehensive
#
# ============================================================================

# ============================================================================
# AFTER SWEEP: ANALYSIS AND NEXT STEPS
# ============================================================================
#
# STEP 1: Collect Results
#   - Combine all matrix_results.csv files
#   - Sort by val_ppl to find best configs
#   - Identify Pareto frontier (quality vs efficiency)
#
# STEP 2: Statistical Analysis
#   - Compare k=0 vs best tree model
#   - Test significance of depth improvements
#   - Analyze sparsity patterns
#
# STEP 3: User Interaction Testing
#   # Find best model path from CSV
#   docker run -it --gpus all \
#     -v ${PWD}/runs:/app/runs \
#     boenet:cuda python infer_boenet.py \
#       --ckpt runs/TIMESTAMP/BEST_RUN/model.pt \
#       --generate \
#       --max_tokens 200 \
#       --temperature 0.8
#
# STEP 4: If Results Are Promising
#   - Develop DYNAMIC DEPTH algorithm
#   - Model decides when to stop expanding
#   - True adaptive computation per input
#
# ============================================================================

# ============================================================================
# FUTURE: DYNAMIC DEPTH ALGORITHM
# ============================================================================
#
# CURRENT (Fixed Depth):
#   max_depth = 4  # Hardcoded
#   # Every input gets same max depth
#
# FUTURE (Dynamic Depth):
#   while policy_says_expand() and depth < max_depth:
#       expand_next_level()
#       depth += 1
#   # Different inputs get different depths!
#
# BENEFITS:
#   - Easy tokens: depth=1-2 (fast, like System 1)
#   - Hard tokens: depth=4-5 (accurate, like System 2)
#   - True adaptive computation
#   - Optimal efficiency per input
#
# This sweep provides the data foundation for:
#   1. Understanding depth-quality relationship
#   2. Setting appropriate max_depth limits
#   3. Training the stopping policy
#   4. Evaluating dynamic vs fixed depth
#
# ============================================================================

# ============================================================================
# VERSION HISTORY
# ============================================================================
#
# v3.2.0 (2026-01-03) - COMPREHENSIVE SWEEP
#   - Enabled by training speedup (hours â†’ minutes)
#   - Full parameter space exploration
#   - k âˆˆ {0, 2, 3, 4}
#   - depth âˆˆ {0, 2, 3, 4, 5}
#   - epochs âˆˆ {5, 10, 15, 20, 25, 30}
#   - 96 total runs, ~8 hours estimated
#
# v3.1.0 (2026-01-01) - Limited sweep (broken training)
#   - k âˆˆ {0, 2}
#   - depth âˆˆ {2, 3, 4}
#   - epochs âˆˆ {10, 20, 30}
#   - Training was slow due to GrowthPolicyNet bug
#
# v2.0.1 - Phase 1/2 sweeps
#   - Initial parameter exploration
#   - Discovered k=2 as best branching factor
#   - Limited by slow training
#
# ============================================================================

# ============================================================================
# SUMMARY
# ============================================================================
#
# This config runs 96 experiments to comprehensively map the BoeNet
# parameter space. Now that training is fast (~5 min/run), we can
# finally answer the key questions:
#
#   1. Is the tree structure worth the complexity?
#   2. What is the optimal (k, depth) combination?
#   3. How does adaptive sparsity affect quality?
#   4. When do models converge?
#
# Results will guide:
#   - Production model selection
#   - Dynamic depth algorithm design
#   - Future architecture improvements
#
# LET'S GO! ðŸš€
#
# ============================================================================